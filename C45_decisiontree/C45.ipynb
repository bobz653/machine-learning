{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree {'outlook': {0: 'N', 1: 'Y', 2: {'temperature': {1: 'Y', 2: {'windy': {0: 'Y', 1: 'N'}}}}}}\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "import operator\n",
    "\n",
    "def count_entropy(dataset):\n",
    "    total_count = len(dataset)\n",
    "    map_labels = {}\n",
    "    labels = [x[-1] for x in dataset]\n",
    "    for label in labels:\n",
    "        map_labels.setdefault(label,0)\n",
    "        map_labels[label] += 1\n",
    "  \n",
    "    entropy = 0.0\n",
    "    for value in map_labels.values():\n",
    "        prob = value * 1.0 / total_count\n",
    "        entropy += - prob  * log(prob , 2)\n",
    "    return entropy\n",
    "\n",
    "def split_dataset(dataset, feature, value):\n",
    "    sub_dataset = []\n",
    "    for item in dataset:\n",
    "        if item[feature] == value:\n",
    "            newitem = item[:feature]\n",
    "            newitem.extend(item[feature+1:])\n",
    "            sub_dataset.append(newitem)\n",
    "    return sub_dataset\n",
    "\n",
    "def getbest_feature(dataset):\n",
    "    base_entropy = count_entropy(dataset)\n",
    "    \n",
    "    best_feature = -1\n",
    "    best_infogain = 0.0\n",
    "    \n",
    "    for i in range(len(dataset[0])-1):\n",
    "        feature_values = set([item[i] for item in dataset])\n",
    "        infogain = 0.0\n",
    "        inforatio = 0.0\n",
    "        for k in feature_values:\n",
    "            subdataset = split_dataset(dataset, i, k)\n",
    "            prob = float(len(subdataset)) / len(dataset) \n",
    "            infogain +=  prob  * count_entropy(subdataset)\n",
    "            inforatio += - prob  * log(prob , 2)    \n",
    "        \n",
    "        if inforatio == 0:\n",
    "            continue\n",
    "        \n",
    "        infogain = (base_entropy - infogain) / inforatio\n",
    "        if inforatio > best_infogain:\n",
    "            best_feature = i\n",
    "            best_infogain = inforatio\n",
    "    \n",
    "    #print 'best_fature',best_feature\n",
    "    return best_feature\n",
    "        \n",
    "    \n",
    "def create_decisiontree(dataset, label):\n",
    "    #print 'dataset',dataset\n",
    "    #print 'lable',label\n",
    "    \n",
    "    #所有数据一个类别\n",
    "    labels = [instance[-1] for instance in dataset]\n",
    "    if labels.count(labels[0]) == len(labels):\n",
    "        return labels[0]\n",
    "\n",
    "    #no data,only labels,当切分的不能再切分的时候\n",
    "    if len(dataset[0]) == 1:\n",
    "        map_labels = {}\n",
    "        labels = [x[-1] for x in dataset]\n",
    "        for res in labels:\n",
    "            map_labels.set_default(res,0)\n",
    "            map_labels[res] += 1\n",
    "        sorted(map_labels.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "        print 'res',map_labels\n",
    "        return map_labels[0][0]\n",
    "    \n",
    "    #count base entropy\n",
    "    i = getbest_feature(dataset)\n",
    "    \n",
    "    feature_name = label[i]\n",
    "    del label[i]\n",
    "    \n",
    "    feature_values = set([item[i] for item in dataset])\n",
    "    \n",
    "    decision_tree = {feature_name:{}}\n",
    "    for val in feature_values:\n",
    "        sub_dataset = split_dataset(dataset, i, val)\n",
    "        decision_tree[feature_name][val] = create_decisiontree(sub_dataset, label)\n",
    "    \n",
    "    return decision_tree\n",
    "\n",
    "def predict(test_data, labels, tree):\n",
    "\n",
    "    root_feature = list(tree.keys())[0]\n",
    "    \n",
    "    feature_idx = labels.index(root_feature)\n",
    "    subtree = tree[root_feature]\n",
    "    label = ''\n",
    "    for item in subtree:\n",
    "        if item == test_data[feature_idx]:\n",
    "            if type(subtree[item]).__name__ == 'dict':\n",
    "                label = predict(test_data, labels, subtree[item])\n",
    "            else:\n",
    "                label = subtree[item]\n",
    "            break\n",
    "    return label\n",
    "    \n",
    "        \n",
    "\n",
    "if '__main__' == __name__:\n",
    "    \n",
    "    train_set = [[0, 0, 0, 0, 'N'], \n",
    "               [0, 0, 0, 1, 'N'], \n",
    "               [1, 0, 0, 0, 'Y'], \n",
    "               [2, 1, 0, 0, 'Y'], \n",
    "               [2, 2, 1, 0, 'Y'], \n",
    "               [2, 2, 1, 1, 'N'], \n",
    "               [1, 2, 1, 1, 'Y']]\n",
    "    labels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "    \n",
    "    \n",
    "    \n",
    "    decision_tree = create_decisiontree(train_set, labels)\n",
    "    \n",
    "    print  'decision tree',decision_tree\n",
    "    test_dataset = [2, 2, 0, 1]\n",
    "    labels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "    print predict(test_dataset, labels, decision_tree)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
