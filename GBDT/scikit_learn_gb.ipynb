{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          78.2922           2.8162            0.70s\n",
      "         2          81.7426           2.0762            0.43s\n",
      "         3          74.3407           2.5626            0.32s\n",
      "         4          73.8844           2.5643            0.26s\n",
      "         5          70.8368           2.1406            0.23s\n",
      "         6          70.1122           1.6746            0.20s\n",
      "         7          61.0798           2.5003            0.19s\n",
      "         8          67.7408           1.3437            0.17s\n",
      "         9          61.0342           2.2634            0.16s\n",
      "        10          55.4914           2.5608            0.16s\n",
      "        11          59.4668           1.8777            0.15s\n",
      "        12          58.2374           1.4695            0.15s\n",
      "        13          51.6274           1.7085            0.14s\n",
      "        14          54.1443           1.4752            0.14s\n",
      "        15          51.5884           1.1835            0.13s\n",
      "        16          52.9998           1.0671            0.13s\n",
      "        17          50.3234           1.1296            0.13s\n",
      "        18          47.7623           1.3298            0.12s\n",
      "        19          48.2363           1.0761            0.12s\n",
      "        20          44.9659           1.2636            0.12s\n",
      "        21          39.0549           1.6061            0.12s\n",
      "        22          41.5864           1.0793            0.12s\n",
      "        23          38.9940           1.0346            0.12s\n",
      "        24          41.3883           0.7306            0.11s\n",
      "        25          40.9730           0.5027            0.11s\n",
      "        26          37.3511           0.7789            0.11s\n",
      "        27          37.7795           0.8391            0.11s\n",
      "        28          33.5571           1.1306            0.11s\n",
      "        29          33.3001           1.0377            0.11s\n",
      "        30          35.1412           0.6435            0.11s\n",
      "        31          34.8885           0.5505            0.10s\n",
      "        32          31.8440           0.4209            0.10s\n",
      "        33          31.4644           0.7587            0.10s\n",
      "        34          31.3817           0.6991            0.10s\n",
      "        35          29.2725           0.7346            0.10s\n",
      "        36          27.3015           0.7166            0.10s\n",
      "        37          30.0678           0.4836            0.10s\n",
      "        38          27.4810           0.4298            0.10s\n",
      "        39          25.4237           0.6961            0.10s\n",
      "        40          26.7843           0.4565            0.09s\n",
      "        41          26.6650           0.3433            0.09s\n",
      "        42          23.4436           0.5039            0.09s\n",
      "        43          23.7562           0.4369            0.09s\n",
      "        44          22.8658           0.3901            0.09s\n",
      "        45          22.2098           0.4146            0.09s\n",
      "        46          22.1052           0.3719            0.09s\n",
      "        47          20.9564           0.5481            0.09s\n",
      "        48          21.4761           0.4408            0.09s\n",
      "        49          20.4803           0.4398            0.09s\n",
      "        50          21.2413           0.2893            0.09s\n",
      "        51          20.4786           0.2259            0.09s\n",
      "        52          19.5504           0.2899            0.09s\n",
      "        53          17.9449           0.4341            0.08s\n",
      "        54          19.8977           0.2408            0.08s\n",
      "        55          18.2466           0.3442            0.08s\n",
      "        56          18.2638           0.3095            0.08s\n",
      "        57          16.4748           0.3203            0.08s\n",
      "        58          16.7762           0.3570            0.08s\n",
      "        59          16.0937           0.4139            0.08s\n",
      "        60          17.6709           0.1805            0.08s\n",
      "        61          14.9377           0.3771            0.08s\n",
      "        62          15.4148           0.2247            0.08s\n",
      "        63          15.2501           0.2779            0.08s\n",
      "        64          15.6836           0.2362            0.08s\n",
      "        65          15.8390           0.1591            0.08s\n",
      "        66          14.9944           0.1384            0.07s\n",
      "        67          14.9982           0.1792            0.07s\n",
      "        68          14.1448           0.1882            0.07s\n",
      "        69          13.5476           0.2287            0.07s\n",
      "        70          12.8101           0.1543            0.07s\n",
      "        71          13.5422           0.1459            0.07s\n",
      "        72          13.0577           0.1670            0.07s\n",
      "        73          12.3033           0.1791            0.07s\n",
      "        74          13.0227           0.2024            0.07s\n",
      "        75          11.8845           0.1791            0.07s\n",
      "        76          12.5440           0.0999            0.07s\n",
      "        77          11.0179           0.2041            0.07s\n",
      "        78          12.3971           0.0931            0.07s\n",
      "        79          10.5660           0.2341            0.07s\n",
      "        80          10.0187           0.1149            0.07s\n",
      "        81          11.0609           0.1006            0.07s\n",
      "        82          11.2642           0.1617            0.07s\n",
      "        83          11.5676           0.1048            0.06s\n",
      "        84          11.2995           0.1192            0.06s\n",
      "        85          10.0252           0.1265            0.06s\n",
      "        86          10.9122           0.1028            0.06s\n",
      "        87          10.5132           0.0474            0.06s\n",
      "        88          10.1398           0.1284            0.06s\n",
      "        89           9.9023           0.0504            0.06s\n",
      "        90           9.0770           0.1076            0.06s\n",
      "        91          10.3922           0.0691            0.06s\n",
      "        92           9.0173           0.0915            0.06s\n",
      "        93           9.0367           0.0802            0.06s\n",
      "        94           9.2560           0.0860            0.06s\n",
      "        95           9.1523           0.0942            0.06s\n",
      "        96           9.3974           0.0124            0.06s\n",
      "        97           9.8366           0.0384            0.06s\n",
      "        98           9.3579           0.0490            0.05s\n",
      "        99           8.9782           0.0913            0.05s\n",
      "       100           8.7189           0.0655            0.05s\n",
      "       101           7.8440           0.0331            0.05s\n",
      "       102           8.6339           0.0407            0.05s\n",
      "       103           8.8972           0.0707            0.05s\n",
      "       104           8.3408           0.0193            0.05s\n",
      "       105           8.3728           0.0515            0.05s\n",
      "       106           8.4623           0.0673            0.05s\n",
      "       107           8.1791           0.0391            0.05s\n",
      "       108           8.4064           0.0359            0.05s\n",
      "       109           7.5929           0.0501            0.05s\n",
      "       110           8.0712           0.0101            0.05s\n",
      "       111           7.5572           0.0881            0.05s\n",
      "       112           7.3002           0.0290            0.05s\n",
      "       113           7.3359           0.0405            0.05s\n",
      "       114           6.7607           0.0433            0.05s\n",
      "       115           7.4459           0.0625            0.05s\n",
      "       116           7.4019           0.0397            0.05s\n",
      "       117           7.3234           0.0506            0.04s\n",
      "       118           6.5769           0.0636            0.04s\n",
      "       119           7.3652           0.0472            0.04s\n",
      "       120           7.2706           0.0198            0.04s\n",
      "       121           6.5365           0.0565            0.04s\n",
      "       122           6.4402           0.0200            0.04s\n",
      "       123           6.9345           0.0042            0.04s\n",
      "       124           6.0285           0.0343            0.04s\n",
      "       125           6.7577           0.0266            0.04s\n",
      "       126           6.7995           0.0037            0.04s\n",
      "       127           6.4220           0.0175            0.04s\n",
      "       128           6.8806           0.0313            0.04s\n",
      "       129           6.1999           0.0374            0.04s\n",
      "       130           6.2696           0.0231            0.04s\n",
      "       131           6.5974           0.0105            0.04s\n",
      "       132           6.1690           0.0371            0.04s\n",
      "       133           6.1218           0.0270            0.04s\n",
      "       134           6.4828           0.0158            0.04s\n",
      "       135           6.1311           0.0126            0.03s\n",
      "       136           5.9608           0.0235            0.03s\n",
      "       137           6.1022           0.0179            0.03s\n",
      "       138           5.9629          -0.0017            0.03s\n",
      "       139           5.9483           0.0178            0.03s\n",
      "       140           5.4335           0.0150            0.03s\n",
      "       141           6.2023           0.0259            0.03s\n",
      "       142           5.9003           0.0070            0.03s\n",
      "       143           5.9292           0.0060            0.03s\n",
      "       144           5.6329           0.0266            0.03s\n",
      "       145           5.6480           0.0127            0.03s\n",
      "       146           5.8382           0.0072            0.03s\n",
      "       147           5.9457           0.0136            0.03s\n",
      "       148           5.1170          -0.0047            0.03s\n",
      "       149           5.6320           0.0177            0.03s\n",
      "       150           5.4543           0.0164            0.03s\n",
      "       151           5.7474           0.0135            0.03s\n",
      "       152           5.5928           0.0083            0.03s\n",
      "       153           5.4576           0.0267            0.02s\n",
      "       154           5.0535           0.0085            0.02s\n",
      "       155           5.6338           0.0089            0.02s\n",
      "       156           5.3208           0.0159            0.02s\n",
      "       157           5.5102           0.0020            0.02s\n",
      "       158           5.2451           0.0087            0.02s\n",
      "       159           4.9706           0.0168            0.02s\n",
      "       160           5.4666           0.0058            0.02s\n",
      "       161           5.4375           0.0038            0.02s\n",
      "       162           5.1368          -0.0056            0.02s\n",
      "       163           5.0202           0.0122            0.02s\n",
      "       164           5.1155           0.0124            0.02s\n",
      "       165           4.7436           0.0116            0.02s\n",
      "       166           4.8079          -0.0009            0.02s\n",
      "       167           5.2792           0.0062            0.02s\n",
      "       168           5.0683           0.0004            0.02s\n",
      "       169           4.8802           0.0100            0.02s\n",
      "       170           4.8568           0.0111            0.02s\n",
      "       171           4.6307           0.0144            0.02s\n",
      "       172           4.9057           0.0178            0.01s\n",
      "       173           4.9476           0.0131            0.01s\n",
      "       174           4.9407           0.0073            0.01s\n",
      "       175           4.9083          -0.0121            0.01s\n",
      "       176           5.0035          -0.0041            0.01s\n",
      "       177           4.7384          -0.0008            0.01s\n",
      "       178           4.8449          -0.0047            0.01s\n",
      "       179           4.8763           0.0050            0.01s\n",
      "       180           4.3996           0.0054            0.01s\n",
      "       181           4.7076           0.0125            0.01s\n",
      "       182           4.6404          -0.0164            0.01s\n",
      "       183           4.8152          -0.0006            0.01s\n",
      "       184           4.4449          -0.0024            0.01s\n",
      "       185           4.2604           0.0097            0.01s\n",
      "       186           4.4997          -0.0010            0.01s\n",
      "       187           4.0723          -0.0146            0.01s\n",
      "       188           4.2061           0.0135            0.01s\n",
      "       189           4.3501          -0.0038            0.01s\n",
      "       190           4.2478           0.0132            0.01s\n",
      "       191           4.3673          -0.0037            0.00s\n",
      "       192           4.2446           0.0002            0.00s\n",
      "       193           4.0186          -0.0045            0.00s\n",
      "       194           4.3791          -0.0026            0.00s\n",
      "       195           4.2546          -0.0047            0.00s\n",
      "       196           4.4670          -0.0056            0.00s\n",
      "       197           4.1793           0.0067            0.00s\n",
      "       198           3.8806          -0.0063            0.00s\n",
      "       199           4.4453          -0.0140            0.00s\n",
      "       200           4.2987          -0.0011            0.00s\n",
      "RMSE for training dataset is 4.209062, for testing dataset is 10.496762.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Output:\\nRMSE for training dataset is 4.239157, for testing dataset is 10.749044.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://www.jianshu.com/p/02cfaae3fd01\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(load_boston().data, load_boston().target, test_size=0.2)\n",
    "\n",
    "\n",
    "\"\"\"初始化算法，设置参数\n",
    "\n",
    "一些主要参数\n",
    "loss: 损失函数，GBDT回归器可选'ls', 'lad', 'huber', 'quantile'。\n",
    "learning_rate: 学习率/步长。\n",
    "n_estimators: 迭代次数，和learning_rate存在trade-off关系。\n",
    "criterion: 衡量分裂质量的公式，一般默认即可。\n",
    "subsample: 样本采样比例。\n",
    "max_features: 最大特征数或比例。\n",
    "\n",
    "决策树相关参数包括max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_leaf_nodes, min_impurity_split, 多数用来设定决策树分裂停止条件。\n",
    "\n",
    "verbose: 日志level。\n",
    "具体说明和其它参数请参考官网API。\n",
    "\"\"\"\n",
    "reg_model = GradientBoostingRegressor(\n",
    "    loss='ls',\n",
    "    learning_rate=0.02,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    max_features=0.8,\n",
    "    max_depth=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# 评估模型\n",
    "prediction_train = reg_model.predict(X_train)\n",
    "rmse_train = mean_squared_error(y_train, prediction_train)\n",
    "prediction_test = reg_model.predict(X_test)\n",
    "rmse_test = mean_squared_error(y_test, prediction_test)\n",
    "print \"RMSE for training dataset is %f, for testing dataset is %f.\" % (rmse_train, rmse_test)\n",
    "\"\"\"\n",
    "Output:\n",
    "RMSE for training dataset is 4.239157, for testing dataset is 10.749044.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1         103.6549           0.4223            0.07s\n",
      "         2         102.0569           0.3399            0.07s\n",
      "         3         100.6466           0.3734            0.07s\n",
      "         4          98.7931           0.4003            0.06s\n",
      "         5          97.4915           0.3363            0.07s\n",
      "         6          95.8733           0.3883            0.07s\n",
      "         7          94.4909           0.3542            0.07s\n",
      "         8          93.3805           0.2342            0.06s\n",
      "         9          91.9886           0.3094            0.06s\n",
      "        10          90.6541           0.3563            0.06s\n",
      "        11          89.2891           0.3070            0.06s\n",
      "        12          88.1824           0.3236            0.06s\n",
      "        13          86.5349           0.3320            0.06s\n",
      "        14          85.5641           0.3242            0.05s\n",
      "        15          83.9235           0.2834            0.05s\n",
      "        16          83.0200           0.2989            0.05s\n",
      "        17          81.7170           0.3393            0.05s\n",
      "        18          80.1080           0.2498            0.05s\n",
      "        19          79.2725           0.2342            0.05s\n",
      "        20          78.6776           0.2426            0.05s\n",
      "        21          77.4548           0.2711            0.04s\n",
      "        22          75.9750           0.2669            0.04s\n",
      "        23          74.9603           0.2387            0.04s\n",
      "        24          73.7098           0.2350            0.04s\n",
      "        25          72.7694           0.2340            0.04s\n",
      "        26          71.9716           0.2583            0.04s\n",
      "        27          70.7886           0.1149            0.03s\n",
      "        28          70.7860           0.1836            0.03s\n",
      "        29          69.7601           0.1908            0.03s\n",
      "        30          68.4329           0.2175            0.03s\n",
      "        31          68.0937           0.2194            0.03s\n",
      "        32          67.2096           0.2133            0.03s\n",
      "        33          66.1146           0.1921            0.03s\n",
      "        34          64.6243           0.1693            0.02s\n",
      "        35          63.9714           0.2274            0.02s\n",
      "        36          63.2241           0.1842            0.02s\n",
      "        37          62.5373           0.2051            0.02s\n",
      "        38          61.8488           0.1926            0.02s\n",
      "        39          61.1644           0.2042            0.02s\n",
      "        40          60.3161           0.1157            0.01s\n",
      "        41          59.6576           0.1655            0.01s\n",
      "        42          57.4189           0.1253            0.01s\n",
      "        43          58.0593           0.1412            0.01s\n",
      "        44          57.1402           0.1690            0.01s\n",
      "        45          56.0055           0.1524            0.01s\n",
      "        46          55.6673           0.1606            0.01s\n",
      "        47          55.5517           0.1597            0.00s\n",
      "        48          55.0805           0.1919            0.00s\n",
      "        49          53.2667           0.1614            0.00s\n",
      "        50          52.9248           0.1424            0.00s\n",
      "Confusion matrix for training dataset is \n",
      "[[39  0  0]\n",
      " [ 0 43  0]\n",
      " [ 0  1 37]]\n",
      " for testing dataset is \n",
      "[[11  0  0]\n",
      " [ 0  6  1]\n",
      " [ 0  1 11]].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Output:\\nConfusion matrix for training dataset is \\n[[40  0  0]\\n [ 0 40  1]\\n [ 0  1 38]]\\n for testing dataset is \\n[[10  0  0]\\n [ 0  8  1]\\n [ 0  0 11]].\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 导入数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(load_iris().data, load_iris().target, test_size=0.2)\n",
    "\n",
    "\n",
    "\"\"\"初始化算法，设置参数\n",
    "\n",
    "一些主要参数\n",
    "loss: 损失函数，GBDT分类器可选'deviance', 'exponential'。\n",
    "learning_rate: 学习率/步长。\n",
    "n_estimators: 迭代次数，和learning_rate存在trade-off关系。\n",
    "criterion: 衡量分裂质量的公式，一般默认即可。\n",
    "subsample: 样本采样比例。\n",
    "max_features: 最大特征数或比例。\n",
    "\n",
    "决策树相关参数包括max_depth, min_samples_split, min_samples_leaf, min_weight_fraction_leaf, max_leaf_nodes, min_impurity_split, 多数用来设定决策树分裂停止条件。\n",
    "\n",
    "verbose: 日志level。\n",
    "具体说明和其它参数请参考官网API。\n",
    "\"\"\"\n",
    "clf_model = GradientBoostingClassifier(\n",
    "    loss='deviance',\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=50,\n",
    "    subsample=0.8,\n",
    "    max_features=1,\n",
    "    max_depth=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "clf_model.fit(X_train, y_train)\n",
    "\n",
    "# 评估模型\n",
    "prediction_train = clf_model.predict(X_train)\n",
    "cm_train = confusion_matrix(y_train, prediction_train)\n",
    "prediction_test = clf_model.predict(X_test)\n",
    "cm_test = confusion_matrix(y_test, prediction_test)\n",
    "print \"Confusion matrix for training dataset is \\n%s\\n for testing dataset is \\n%s.\" % (cm_train, cm_test)\n",
    "\"\"\"Output:\n",
    "Confusion matrix for training dataset is \n",
    "[[40  0  0]\n",
    " [ 0 40  1]\n",
    " [ 0  1 38]]\n",
    " for testing dataset is \n",
    "[[10  0  0]\n",
    " [ 0  8  1]\n",
    " [ 0  0 11]].\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
